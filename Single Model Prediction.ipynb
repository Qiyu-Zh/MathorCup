{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from tqdm import tqdm\n",
    "from tpot.builtins import StackingEstimator\n",
    "from tpot.export_utils import set_param_recursive\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import ElasticNetCV\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def criterion(pred, y):\n",
    "    t_pred = np.exp(pred) - 1\n",
    "    t_y = np.exp(y) - 1\n",
    "    dy = np.abs(t_pred - t_y) / t_y\n",
    "    mape = np.sum(dy) / len(t_y)\n",
    "    acc = len(dy[dy <= 0.05]) / len(t_y)\n",
    "    return 0.2 * (1 - mape) + 0.8 * acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictUsingOne(model):\n",
    "    df = pd.read_csv('input/inputTrain.csv')\n",
    "    df.drop(columns=['Unnamed: 0'], inplace=True)\n",
    "\n",
    "    batch_size = int(np.ceil(len(df) / 10))\n",
    "    pred_price = []\n",
    "    for i in tqdm(range(len(df) // batch_size + 1)):\n",
    "        drop_ids = df[i * batch_size : (i + 1) * batch_size]['carid'].values\n",
    "        \n",
    "        dropped_train_df = df[~df['carid'].isin(drop_ids)]\n",
    "        pred_df = df[df['carid'].isin(drop_ids)]\n",
    "        \n",
    "        X_train = dropped_train_df.drop(columns=['price', 'carid']).to_numpy()\n",
    "        y_train = dropped_train_df['price'].values\n",
    "        X_test = pred_df.drop(columns=['price', 'carid']).to_numpy()\n",
    "\n",
    "        f = model\n",
    "        f.fit(X_train, y_train)\n",
    "        pred_price += f.predict(X_test).tolist()\n",
    "    return pred_price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting Models:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [02:28<00:00, 21.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Predicting:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:00<?, ?it/s]\n",
      " 10%|█         | 1/10 [02:28<22:15, 148.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting Models:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [02:30<00:00, 21.52s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Predicting:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:00<?, ?it/s]\n",
      " 20%|██        | 2/10 [04:59<19:59, 149.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting Models:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [02:26<00:00, 20.93s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Predicting:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:00<?, ?it/s]\n",
      " 30%|███       | 3/10 [07:26<17:19, 148.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting Models:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [02:21<00:00, 20.28s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Predicting:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:00<00:00, 7000.51it/s]\n",
      " 40%|████      | 4/10 [09:48<14:36, 146.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting Models:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [02:23<00:00, 20.47s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Predicting:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:00<00:00, 6995.50it/s]\n",
      " 50%|█████     | 5/10 [12:12<12:05, 145.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting Models:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [02:22<00:00, 20.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Predicting:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:00<?, ?it/s]\n",
      " 60%|██████    | 6/10 [14:35<09:37, 144.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting Models:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [02:26<00:00, 20.98s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Predicting:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:00<00:00, 7002.18it/s]\n",
      " 70%|███████   | 7/10 [17:02<07:15, 145.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting Models:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [02:27<00:00, 21.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Predicting:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:00<?, ?it/s]\n",
      " 80%|████████  | 8/10 [19:29<04:52, 146.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting Models:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [02:22<00:00, 20.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Predicting:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:00<00:00, 7000.51it/s]\n",
      " 90%|█████████ | 9/10 [21:52<02:25, 145.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting Models:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [02:25<00:00, 20.79s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Predicting:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:00<?, ?it/s]\n",
      "100%|██████████| 10/10 [24:18<00:00, 145.86s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5721835946336085\n"
     ]
    }
   ],
   "source": [
    "# model = make_pipeline(\n",
    "#             StackingEstimator(estimator=xgb.XGBRegressor(learning_rate=0.001,\n",
    "#                                                             max_depth=1,\n",
    "#                                                             min_child_weight=2,\n",
    "#                                                             n_estimators=100,\n",
    "#                                                             objective='reg:squarederror',\n",
    "#                                                             subsample=0.6500000000000001)\n",
    "#                                                         ),\n",
    "#             RandomForestRegressor(bootstrap=False,\n",
    "#                                     max_features=0.5,\n",
    "#                                     min_samples_leaf=2,\n",
    "#                                     min_samples_split=2\n",
    "#                                     )\n",
    "#         )\n",
    "# predic_name = 'XGBandRFR'\n",
    "\n",
    "\n",
    "\n",
    "# model = make_pipeline(\n",
    "#     StackingEstimator(estimator=RandomForestRegressor(\n",
    "#         bootstrap=True,\n",
    "#         max_features=0.5,\n",
    "#         min_samples_leaf=1,\n",
    "#         min_samples_split=11,\n",
    "#         n_estimators=100)),\n",
    "#     RandomForestRegressor(bootstrap=False,\n",
    "#                         max_features=0.35000000000000003,\n",
    "#                         min_samples_leaf=8,\n",
    "#                         min_samples_split=17,\n",
    "#                         n_estimators=100\n",
    "#                         )\n",
    "# )\n",
    "# predic_name = 'RFRandRFR'\n",
    "\n",
    "\n",
    "\n",
    "# model = RandomForestRegressor(bootstrap=False,\n",
    "#                                 max_features=0.5,\n",
    "#                                 min_samples_leaf=2,\n",
    "#                                 min_samples_split=2,\n",
    "#                                 n_estimators=100\n",
    "#                                 )\n",
    "# setattr(model, 'random_state', 42)\n",
    "# predic_name = 'RFR'\n",
    "\n",
    "\n",
    "\n",
    "# parameters = {'eta': 0.1, 'eval_metric': 'mae', 'gamma': 0.1, 'max_depth': 13, 'n_estimators': 190}\n",
    "# model = xgb.XGBRegressor(**parameters)\n",
    "# predic_name = 'XGB'\n",
    "\n",
    "\n",
    "\n",
    "# model = GradientBoostingRegressor(alpha=0.99,\n",
    "#                                     learning_rate=0.1,\n",
    "#                                     loss='lad',\n",
    "#                                     max_depth=9,\n",
    "#                                     max_features=0.6,\n",
    "#                                     min_samples_leaf=14,\n",
    "#                                     min_samples_split=10,\n",
    "#                                     n_estimators=100,\n",
    "#                                     subsample=1.0\n",
    "#                                     )\n",
    "# predic_name = 'GBR'\n",
    "\n",
    "\n",
    "\n",
    "# model = make_pipeline(\n",
    "#     StackingEstimator(estimator=ExtraTreesRegressor(\n",
    "#         bootstrap=False,\n",
    "#         max_features=0.4,\n",
    "#         min_samples_leaf=1,\n",
    "#         min_samples_split=10,\n",
    "#         n_estimators=100)\n",
    "#         ),\n",
    "#     RandomForestRegressor(bootstrap=False,\n",
    "#                         max_features=0.55,\n",
    "#                         min_samples_leaf=12,\n",
    "#                         min_samples_split=16,\n",
    "#                         n_estimators=100\n",
    "#                         )\n",
    "# )\n",
    "# predic_name = 'ETRandRFR'\n",
    "\n",
    "\n",
    "\n",
    "# model = GradientBoostingRegressor(alpha=0.99,\n",
    "#                                             learning_rate=0.1,\n",
    "#                                             loss=\"huber\",\n",
    "#                                             max_depth=9,\n",
    "#                                             max_features=0.6000000000000001,\n",
    "#                                             min_samples_leaf=8,\n",
    "#                                             min_samples_split=10,\n",
    "#                                             n_estimators=100,\n",
    "#                                             subsample=1.0\n",
    "#                                             )\n",
    "\n",
    "# predic_name = 'GBR_enhanced'\n",
    "\n",
    "\n",
    "# def mape(dtrain, preds):\n",
    "#     d = preds - dtrain\n",
    "#     h = 1\n",
    "#     scale = 1 + (d / h) ** 2\n",
    "#     scale_sqrt = np.sqrt(scale)\n",
    "#     grad = d / scale_sqrt\n",
    "#     hess = 1 / scale / scale_sqrt\n",
    "#     return grad, hess\n",
    "    \n",
    "# model = xgb.XGBRegressor(eta=0.1,\n",
    "#                             gamma=0,\n",
    "#                             max_depth=12,\n",
    "#                             n_estimators=230,\n",
    "#                             objective=mape\n",
    "#                             )\n",
    "\n",
    "# predic_name = 'XGB_enhanced'\n",
    "\n",
    "\n",
    "# model = RandomForestRegressor(bootstrap=False,\n",
    "#                               max_features=0.5,\n",
    "#                               min_samples_leaf=3,\n",
    "#                               min_samples_split=5,\n",
    "#                               n_estimators=100)\n",
    "\n",
    "# predic_name = 'RFR_enhanced'\n",
    "\n",
    "\n",
    "# model = make_pipeline(\n",
    "#     StackingEstimator(estimator=ElasticNetCV(l1_ratio=0.8, tol=0.001)),\n",
    "#     StackingEstimator(estimator=ExtraTreesRegressor(bootstrap=True, max_features=0.55, min_samples_leaf=2, min_samples_split=17, n_estimators=100)),\n",
    "#     RandomForestRegressor(bootstrap=False, max_features=0.4, min_samples_leaf=8, min_samples_split=14, n_estimators=100)\n",
    "# )\n",
    "\n",
    "# predic_name = 'RFRandETRandENCV'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from Final_Model import Model\n",
    "\n",
    "model = Model()\n",
    "\n",
    "predic_name = 'Stacking_model'\n",
    "\n",
    "# price_df = pd.read_csv('input/inputTrain.csv')\n",
    "# price_df = price_df[['carid', 'price']]\n",
    "\n",
    "price_df = pd.read_csv('pricePrediction.csv')\n",
    "price_df.drop(columns=['Unnamed: 0'], inplace=True)\n",
    "price_df[predic_name] = predictUsingOne(model)\n",
    "price_df.to_csv('pricePrediction.csv')\n",
    "print(criterion(price_df[predic_name].values, price_df['price'].values))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 ('pytorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0747f93ff6db21b2db2bf35ad4858dd0825b9c21797c41b4cc32097944ab3f10"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
